{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "17-hardware-acceleration-architecture-overview.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMuKvZcosXWV5Qyy3GMuNGy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dlsys10714/notebooks/blob/main/17_hardware_acceleration_architecture_overview.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mpn1ti5Urdsv"
      },
      "source": [
        "# Lecture 17: Hardware Acceleration Architecture Overview \n",
        "\n",
        "In this lecture, we will to walk through backend scafoldings to get us hardware accelerations for needle.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MkXPIjVd90z7"
      },
      "source": [
        "## Select a GPU runtime type\n",
        "In this lecture, we are going to make use of c++ and CUDA to build accelerated linear algebra libraries. In order to do so, please make sure you select a runtime type with GPU and rerun the cells if needed:\n",
        "- Click on the \"Runtime\" tab\n",
        "- Click \"Change runtime type\"\n",
        "- Select GPU\n",
        "\n",
        "After you started the right runtime, you can run the following command to check if there is a GPU available."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5VM6IcuZ-kv6",
        "outputId": "8c8d5404-fc78-40ee-8422-f7dbceb59e25"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Oct 31 22:37:42 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.29.05    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   58C    P8    33W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXysoqn-vZuF"
      },
      "source": [
        "## Prepare the codebase\n",
        "\n",
        "To get started, we can clone the related lecture13 repo from the github. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjEIRTyr8ajf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f43729d7-751d-4e92-dc37-7fe6a655563a"
      },
      "source": [
        "# Code to set up the assignment\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/\n",
        "!mkdir -p 10714\n",
        "%cd /content/drive/MyDrive/10714\n",
        "# comment out the following line if you run it for the second time\n",
        "# as you already have a local copy of lecture17\n",
        "!rm -rf lecture17\n",
        "!git clone https://github.com/dlsys10714/lecture17\n",
        "!ln -s /content/drive/MyDrive/10714/lecture17 /content/needle"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive\n",
            "/content/drive/MyDrive/10714\n",
            "Cloning into 'lecture17'...\n",
            "remote: Enumerating objects: 134, done.\u001b[K\n",
            "remote: Counting objects: 100% (134/134), done.\u001b[K\n",
            "remote: Compressing objects: 100% (63/63), done.\u001b[K\n",
            "remote: Total 134 (delta 52), reused 133 (delta 51), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (134/134), 11.19 MiB | 9.45 MiB/s, done.\n",
            "Resolving deltas: 100% (52/52), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xe3vClsD9jlq",
        "outputId": "a62920a4-e051-404b-d1eb-c492dccbfd15"
      },
      "source": [
        "!python3 -m pip install pybind11"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pybind11\n",
            "  Downloading pybind11-2.8.1-py2.py3-none-any.whl (208 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▋                              | 10 kB 20.5 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 20 kB 25.3 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 30 kB 12.8 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 40 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 51 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 61 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 71 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 81 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 92 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 102 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 112 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 122 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 133 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 143 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 153 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 163 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 174 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 184 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 194 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 204 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 208 kB 4.3 MB/s \n",
            "\u001b[?25hInstalling collected packages: pybind11\n",
            "Successfully installed pybind11-2.8.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_RrW38i_JNp"
      },
      "source": [
        "### Build the needle cuda library\n",
        "\n",
        "We leverage pybind to build a c++/cuda library for acceleration. You can type make to build the corresponding library."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0EdAcB19saK",
        "outputId": "86eba937-9819-4de3-8994-434a1f4033bb"
      },
      "source": [
        "%cd /content/needle\n",
        "!make"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/10714/lecture17\n",
            "-- The C compiler identification is GNU 7.5.0\n",
            "-- The CXX compiler identification is GNU 7.5.0\n",
            "-- Check for working C compiler: /usr/bin/cc\n",
            "-- Check for working C compiler: /usr/bin/cc -- works\n",
            "-- Detecting C compiler ABI info\n",
            "-- Detecting C compiler ABI info - done\n",
            "-- Detecting C compile features\n",
            "-- Detecting C compile features - done\n",
            "-- Check for working CXX compiler: /usr/bin/c++\n",
            "-- Check for working CXX compiler: /usr/bin/c++ -- works\n",
            "-- Detecting CXX compiler ABI info\n",
            "-- Detecting CXX compiler ABI info - done\n",
            "-- Detecting CXX compile features\n",
            "-- Detecting CXX compile features - done\n",
            "-- Found Python: /usr/bin/python3.7 (found version \"3.7.12\") found components:  Development Interpreter \n",
            "-- Performing Test HAS_FLTO\n",
            "-- Performing Test HAS_FLTO - Success\n",
            "-- Found pybind11: /usr/local/lib/python3.7/dist-packages/pybind11/include (found version \"2.8.1\" )\n",
            "-- Looking for pthread.h\n",
            "-- Looking for pthread.h - found\n",
            "-- Looking for pthread_create\n",
            "-- Looking for pthread_create - not found\n",
            "-- Looking for pthread_create in pthreads\n",
            "-- Looking for pthread_create in pthreads - not found\n",
            "-- Looking for pthread_create in pthread\n",
            "-- Looking for pthread_create in pthread - found\n",
            "-- Found Threads: TRUE  \n",
            "-- Found CUDA: /usr/local/cuda (found version \"11.1\") \n",
            "-- Found cuda, building cuda backend\n",
            "-- Autodetected CUDA architecture(s):  3.7\n",
            "-- Configuring done\n",
            "-- Generating done\n",
            "-- Build files have been written to: /content/drive/MyDrive/10714/lecture17/build\n",
            "make[1]: Entering directory '/content/drive/MyDrive/10714/lecture17/build'\n",
            "make[2]: Entering directory '/content/drive/MyDrive/10714/lecture17/build'\n",
            "make[3]: Entering directory '/content/drive/MyDrive/10714/lecture17/build'\n",
            "[-25%] \u001b[34m\u001b[1mBuilding NVCC (Device) object CMakeFiles/ndarray_backend_cuda.dir/src/ndarray_backend_cuda_generated_ndarray_backend_cuda.cu.o\u001b[0m\n",
            "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
            "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
            "\u001b[35m\u001b[1mScanning dependencies of target ndarray_backend_cuda\u001b[0m\n",
            "make[3]: Leaving directory '/content/drive/MyDrive/10714/lecture17/build'\n",
            "make[3]: Entering directory '/content/drive/MyDrive/10714/lecture17/build'\n",
            "[  0%] \u001b[32m\u001b[1mLinking CXX shared module ../python/needle/backend_ndarray/ndarray_backend_cuda.cpython-37m-x86_64-linux-gnu.so\u001b[0m\n",
            "make[3]: Leaving directory '/content/drive/MyDrive/10714/lecture17/build'\n",
            "[  0%] Built target ndarray_backend_cuda\n",
            "make[3]: Entering directory '/content/drive/MyDrive/10714/lecture17/build'\n",
            "\u001b[35m\u001b[1mScanning dependencies of target ndarray_backend_cpu\u001b[0m\n",
            "make[3]: Leaving directory '/content/drive/MyDrive/10714/lecture17/build'\n",
            "make[3]: Entering directory '/content/drive/MyDrive/10714/lecture17/build'\n",
            "[ 25%] \u001b[32mBuilding CXX object CMakeFiles/ndarray_backend_cpu.dir/src/ndarray_backend_cpu.cc.o\u001b[0m\n",
            "[ 50%] \u001b[32m\u001b[1mLinking CXX shared module ../python/needle/backend_ndarray/ndarray_backend_cpu.cpython-37m-x86_64-linux-gnu.so\u001b[0m\n",
            "make[3]: Leaving directory '/content/drive/MyDrive/10714/lecture17/build'\n",
            "[ 50%] Built target ndarray_backend_cpu\n",
            "make[2]: Leaving directory '/content/drive/MyDrive/10714/lecture17/build'\n",
            "make[1]: Leaving directory '/content/drive/MyDrive/10714/lecture17/build'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFxG3p3S1sBq"
      },
      "source": [
        "We can then run the following command to make the path to the package available in colab's environment as well as the PYTHONPATH."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bix8OXLuCOKt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "828fddc0-c722-4838-fc4d-eb3865777450"
      },
      "source": [
        "%set_env PYTHONPATH /content/needle/python:/env/python\n",
        "import sys\n",
        "sys.path.append(\"/content/needle/python\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: PYTHONPATH=/content/needle/python:/env/python\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBIuE2jc1DaU"
      },
      "source": [
        "## Codebase walkthrough\n",
        "\n",
        "\n",
        "Now click the files panel on the left side. You should be able to see these files\n",
        "\n",
        "Python:\n",
        "- needle/backend_ndarray/ndarray.py\n",
        "- needle/backend_ndarray/ndarray_backend_numpy.py\n",
        "\n",
        "C++/CUDA\n",
        "- src/ndarray_backend_cpu.cc\n",
        "- src/ndarray_backend_cuda.cu\n",
        "\n",
        "The main goal of this lecture is to create an accelerated ndarray library.\n",
        "As a result, we do not need to deal with needle.Tensor for now and will focus on backend_ndarray's implementation. After we build the array library, we can then use it to power the array computation in needle.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1Z8wSsI6PrU"
      },
      "source": [
        "## Creating a CUDA NDArray\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2bm_WB9uF4V"
      },
      "source": [
        "from needle import backend_ndarray as nd"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2On4NzNggDfN"
      },
      "source": [
        "x = nd.NDArray([1, 2, 3])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBlbinVMYNhA"
      },
      "source": [
        "y = x + x"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4RytYKfY6JQ",
        "outputId": "c7711dd3-1ead-493b-8328-dada2dce4a95"
      },
      "source": [
        "y"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NDArray([2. 4. 6.], device=numpy_device())"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZGnTUsKF1x1"
      },
      "source": [
        "We can create a CUDA tensor from the data by specifying a device keyword."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1h5iAYFfBRED"
      },
      "source": [
        "x = nd.NDArray([1, 2, 3], device=nd.cuda())"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CulMPqJkhkpE"
      },
      "source": [
        "y = x + 1"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4UuEs9KAkDR",
        "outputId": "240be7bb-878b-49d7-a7ab-9f9ffc1f4948"
      },
      "source": [
        "x.numpy()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 2., 3.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBMvL6QEBtG7",
        "outputId": "cad5aa89-a523-4303-c4a7-a4747d0d5ea7"
      },
      "source": [
        "x.device"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "cuda()"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJSv7D8NGfAr"
      },
      "source": [
        "y = x + 1"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZ7hmyBVGhGd",
        "outputId": "05c9bc2b-fae1-4f5c-ef3a-5ea8dfa39835"
      },
      "source": [
        "y.device"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "cuda()"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQVtUgK-f7_y",
        "outputId": "b15576da-913e-4fec-e8db-9d7845b635d8"
      },
      "source": [
        "y.numpy()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2., 3., 4.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPjNJfJsf_T9"
      },
      "source": [
        "### Key Data Structures\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxKF9dcFhTy3"
      },
      "source": [
        "## Trace GPU execution\n",
        "\n",
        "Now, let us take a look at what happens when we execute the following code\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLLzZzuthhBH"
      },
      "source": [
        "x = nd.NDArray([1, 2, 3])\n",
        "y = x + 1"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xU5PFJJ-iR7J"
      },
      "source": [
        "Have the following trace:\n",
        "\n",
        "backend_ndarray/ndarray.py\n",
        "- `NDArray.__add__`\n",
        "- `NDArray.ewise_or_scalar`\n",
        "- `ndarray_backend_cpu.cc:ScalarAdd`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxAKyM6yjr_R",
        "outputId": "25f22e91-4c64-4449-fa43-8ca4b08812e5"
      },
      "source": [
        "y.numpy()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2., 3., 4.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4vqb_a4j2O8"
      },
      "source": [
        "Have the following trace:\n",
        "\n",
        "- `NDArray.numpy`\n",
        "- `ndarray_backend_cpu.cc:to_numpy`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMiFJmJVlD6j"
      },
      "source": [
        "## Guidelines for Reading C++/CUDA related Files\n",
        "\n",
        "Read\n",
        "- src/ndarray_backend_cpu.cc\n",
        "- src/ndarray_backend_cuda.cu\n",
        "\n",
        "\n",
        "Optional\n",
        "- CMakeLists.txt: this is used to setup the build and likely you do not need to tweak it.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEpPbwQKkSkZ"
      },
      "source": [
        "## NDArray Data Structure\n",
        "\n",
        "Open up `python/needle/backend_ndarray/ndarray.py`.\n",
        "\n",
        "An NDArray contains the following fields:\n",
        "- handle: The backend handle that build a flat array which stores the data.\n",
        "- shape: The shape of the NDArray\n",
        "- strides: The strides that shows how do we access multi-dimensional elements\n",
        "- offset: The offset of the first element.\n",
        "- device: The backend device that backs the computation\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ONkZbUuj6Dx"
      },
      "source": [
        "## CUDA Acceleration\n",
        "\n",
        "Now let us open `src/ndarray_cuda_backend.cu` and take a look at current implementation of GPU ops.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Og8N3iuZiZ4g"
      },
      "source": [
        "## Steps for adding a new operator implementation\n",
        "- Add an implementation in `ndarray_backend_cuda.cu`, expose via pybind\n",
        "- Call into the operator in ndarray.py\n",
        "- Write up testcases"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xV1I7I2lkOJG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cea55b85-e4f0-440d-a906-018a38397686"
      },
      "source": [
        "!make"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- Found pybind11: /usr/local/lib/python3.7/dist-packages/pybind11/include (found version \"2.8.1\" )\n",
            "-- Found cuda, building cuda backend\n",
            "-- Autodetected CUDA architecture(s):  3.7\n",
            "-- Configuring done\n",
            "-- Generating done\n",
            "-- Build files have been written to: /content/drive/MyDrive/10714/lecture17/build\n",
            "make[1]: Entering directory '/content/drive/MyDrive/10714/lecture17/build'\n",
            "make[2]: Entering directory '/content/drive/MyDrive/10714/lecture17/build'\n",
            "make[3]: Entering directory '/content/drive/MyDrive/10714/lecture17/build'\n",
            "make[3]: Leaving directory '/content/drive/MyDrive/10714/lecture17/build'\n",
            "make[3]: Entering directory '/content/drive/MyDrive/10714/lecture17/build'\n",
            "[-25%] \u001b[32m\u001b[1mLinking CXX shared module ../python/needle/backend_ndarray/ndarray_backend_cuda.cpython-37m-x86_64-linux-gnu.so\u001b[0m\n",
            "make[3]: Leaving directory '/content/drive/MyDrive/10714/lecture17/build'\n",
            "[  0%] Built target ndarray_backend_cuda\n",
            "make[3]: Entering directory '/content/drive/MyDrive/10714/lecture17/build'\n",
            "make[3]: Leaving directory '/content/drive/MyDrive/10714/lecture17/build'\n",
            "[ 50%] Built target ndarray_backend_cpu\n",
            "make[2]: Leaving directory '/content/drive/MyDrive/10714/lecture17/build'\n",
            "make[1]: Leaving directory '/content/drive/MyDrive/10714/lecture17/build'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dobDH96Ql8SV"
      },
      "source": [
        "import needle as ndl\n",
        "x = ndl.Tensor([1,2,3], device=ndl.cuda(), dtype=\"float32\")\n",
        "y = ndl.Tensor([2,3,5], device=ndl.cuda(), dtype=\"float32\")\n",
        "x + y\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5L8M3DGmGhH",
        "outputId": "ed8c9c98-592c-4a87-f9fb-8207ddb515a5"
      },
      "source": [
        "!nvprof python tests/test_backend_ndarray.py"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 2, 3)\n",
            "==884== NVPROF is profiling process 884, command: python3 tests/test_backend_ndarray.py\n",
            "==884== Warning: Auto boost enabled on device 0. Profiling results may be inconsistent.\n",
            "==884== Profiling application: python3 tests/test_backend_ndarray.py\n",
            "==884== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   47.53%  4.9280us         2  2.4640us  2.3680us  2.5600us  [CUDA memcpy DtoH]\n",
            "                   30.25%  3.1360us         1  3.1360us  3.1360us  3.1360us  needle::cuda::ScalarAddKernel(float const *, float, float*, unsigned long)\n",
            "                   22.22%  2.3040us         1  2.3040us  2.3040us  2.3040us  [CUDA memcpy HtoD]\n",
            "      API calls:   99.61%  248.01ms         2  124.00ms  8.5630us  248.00ms  cudaMalloc\n",
            "                    0.19%  473.07us         1  473.07us  473.07us  473.07us  cuDeviceTotalMem\n",
            "                    0.09%  223.82us       101  2.2150us     160ns  102.07us  cuDeviceGetAttribute\n",
            "                    0.06%  138.27us         2  69.133us  11.803us  126.46us  cudaFree\n",
            "                    0.03%  77.815us         3  25.938us  23.565us  27.945us  cudaMemcpy\n",
            "                    0.01%  28.172us         1  28.172us  28.172us  28.172us  cudaLaunchKernel\n",
            "                    0.01%  26.953us         1  26.953us  26.953us  26.953us  cuDeviceGetName\n",
            "                    0.00%  9.6850us         1  9.6850us  9.6850us  9.6850us  cuDeviceGetPCIBusId\n",
            "                    0.00%  2.2550us         3     751ns     198ns  1.2400us  cuDeviceGetCount\n",
            "                    0.00%  1.9350us         2     967ns     326ns  1.6090us  cuDeviceGet\n",
            "                    0.00%     297ns         1     297ns     297ns     297ns  cuDeviceGetUuid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74OUUH2REG18"
      },
      "source": [
        "## Write Standalone Python Test Files\n",
        "\n",
        "Now that we have additional c++/cuda libraries in needle, we will need to type make in order to rebuild the library. Additionally, because the colab environment caches the old library, it is inconvenient to use the ipython cells to debug the updated library.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgLoV-_KHAM3",
        "outputId": "90f22a99-1da9-4243-a472-efd67a136c6b"
      },
      "source": [
        "!make"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- Found pybind11: /usr/local/lib/python3.7/dist-packages/pybind11/include (found version \"2.8.1\" )\n",
            "-- Found cuda, building cuda backend\n",
            "-- Autodetected CUDA architecture(s):  3.7\n",
            "-- Configuring done\n",
            "-- Generating done\n",
            "-- Build files have been written to: /content/drive/MyDrive/10714/lecture17/build\n",
            "make[1]: Entering directory '/content/drive/MyDrive/10714/lecture17/build'\n",
            "make[2]: Entering directory '/content/drive/MyDrive/10714/lecture17/build'\n",
            "make[3]: Entering directory '/content/drive/MyDrive/10714/lecture17/build'\n",
            "make[3]: Leaving directory '/content/drive/MyDrive/10714/lecture17/build'\n",
            "[  0%] Built target ndarray_backend_cuda\n",
            "make[3]: Entering directory '/content/drive/MyDrive/10714/lecture17/build'\n",
            "make[3]: Leaving directory '/content/drive/MyDrive/10714/lecture17/build'\n",
            "[ 50%] Built target ndarray_backend_cpu\n",
            "make[2]: Leaving directory '/content/drive/MyDrive/10714/lecture17/build'\n",
            "make[1]: Leaving directory '/content/drive/MyDrive/10714/lecture17/build'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dudnLHRqoKY2"
      },
      "source": [
        "\n",
        "We recommend writing separate python files and invoke them from the command line. Create a new file `tests/mytest.py` and write your local tests. This is also a common develop practice in big projects that involves python c++ FFI."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TubIHJrkn4Sk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16be483a-adbf-4ea3-8750-308e501b4540"
      },
      "source": [
        "!python tests/mytest.py"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python3: can't open file 'tests/mytest.py': [Errno 2] No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ei0UR-FYoY1-"
      },
      "source": [
        "After we have building the library, we could choose to fully restart the runtime (factory reset runtime) if you want to bring the updated change back to another colab. Note that you will need to save your code changes to the drive or a private github repo."
      ]
    }
  ]
}