{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "13-hardware-acceleration-implementation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPdGEeF+dP3mf4UNQ+YQxuF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dlsys10714/notebooks/blob/main/13_hardware_acceleration_implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mpn1ti5Urdsv"
      },
      "source": [
        "# Lecture 13: Hardware Acceleration Implementation \n",
        "\n",
        "In this lecture, we will to walk through backend scafoldings to get us hardware accelerations for needle.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MkXPIjVd90z7"
      },
      "source": [
        "## Select a GPU runtime type\n",
        "In this lecture, we are going to make use of c++ and CUDA to build accelerated linear algebra libraries. In order to do so, please make sure you select a runtime type with GPU and rerun the cells if needed:\n",
        "- Click on the \"Runtime\" tab\n",
        "- Click \"Change runtime type\"\n",
        "- Select GPU\n",
        "\n",
        "After you started the right runtime, you can run the following command to check if there is a GPU available."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5VM6IcuZ-kv6",
        "outputId": "8220b42f-4102-4fe2-ccb4-83d49fe68454"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Oct 13 15:15:56 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.74       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P8    27W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXysoqn-vZuF"
      },
      "source": [
        "## Prepare the codebase\n",
        "\n",
        "To get started, we can clone the related lecture13 repo from the github. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjEIRTyr8ajf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e266941-a54c-4dbe-baaa-550742e8fd65"
      },
      "source": [
        "# Code to set up the assignment\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/\n",
        "!mkdir -p 10714\n",
        "%cd /content/drive/MyDrive/10714\n",
        "# comment out the following line if you run it for the second time\n",
        "# as you already have a local copy of lecture13\n",
        "!git clone https://github.com/dlsys10714/lecture13 \n",
        "!ln -s /content/drive/MyDrive/10714/lecture13 /content/needle"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive\n",
            "/content/drive/MyDrive/10714\n",
            "fatal: destination path 'lecture13' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xe3vClsD9jlq",
        "outputId": "451b1e0e-d846-4b4a-a7eb-1c904f80e007"
      },
      "source": [
        "!python3 -m pip install pybind11"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pybind11\n",
            "  Downloading pybind11-2.8.0-py2.py3-none-any.whl (207 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▋                              | 10 kB 26.4 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 20 kB 19.8 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 30 kB 10.5 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 40 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 51 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 61 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 71 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 81 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 92 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 102 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 112 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 122 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 133 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 143 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 153 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 163 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 174 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 184 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 194 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 204 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 207 kB 4.1 MB/s \n",
            "\u001b[?25hInstalling collected packages: pybind11\n",
            "Successfully installed pybind11-2.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_RrW38i_JNp"
      },
      "source": [
        "### Build the needle cuda library\n",
        "\n",
        "We leverage pybind to build a c++/cuda library for acceleration. You can type make to build the corresponding library."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0EdAcB19saK",
        "outputId": "d552e2a8-4887-45ee-a22f-ee44ab12d638"
      },
      "source": [
        "%cd /content/needle\n",
        "!make"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/10714/lecture13\n",
            "-- Found pybind11: /usr/local/lib/python3.7/dist-packages/pybind11/include (found version \"2.8.0\" )\n",
            "-- Find cuda, build with cuda support\n",
            "-- Autodetected CUDA architecture(s):  3.7\n",
            "-- Configuring done\n",
            "-- Generating done\n",
            "-- Build files have been written to: /content/drive/MyDrive/10714/lecture13/build\n",
            "make[1]: Entering directory '/content/drive/MyDrive/10714/lecture13/build'\n",
            "make[2]: Entering directory '/content/drive/MyDrive/10714/lecture13/build'\n",
            "make[3]: Entering directory '/content/drive/MyDrive/10714/lecture13/build'\n",
            "\u001b[35m\u001b[1mScanning dependencies of target main\u001b[0m\n",
            "make[3]: Leaving directory '/content/drive/MyDrive/10714/lecture13/build'\n",
            "make[3]: Entering directory '/content/drive/MyDrive/10714/lecture13/build'\n",
            "[-14%] \u001b[32mBuilding CXX object CMakeFiles/main.dir/python/pybind/main.cc.o\u001b[0m\n",
            "[  0%] \u001b[32m\u001b[1mLinking CXX shared module ../python/needle/_ffi/main.cpython-37m-x86_64-linux-gnu.so\u001b[0m\n",
            "make[3]: Leaving directory '/content/drive/MyDrive/10714/lecture13/build'\n",
            "[ 71%] Built target main\n",
            "make[2]: Leaving directory '/content/drive/MyDrive/10714/lecture13/build'\n",
            "make[1]: Leaving directory '/content/drive/MyDrive/10714/lecture13/build'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFxG3p3S1sBq"
      },
      "source": [
        "We can then run the following command to make the path to the package available in colab's environment as well as the PYTHONPATH."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bix8OXLuCOKt"
      },
      "source": [
        "%set_env PYTHONPATH /content/needle/python:/env/python\n",
        "import sys\n",
        "sys.path.append(\"/content/needle/python\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBIuE2jc1DaU"
      },
      "source": [
        "## Codebase walkthrough\n",
        "\n",
        "\n",
        "Now click the files panel on the left side. You should be able to see these new files:\n",
        "\n",
        "- needle/include/needle\n",
        "    - cuda_ops.h\n",
        "    - device_api.h\n",
        "    - dlpack.h\n",
        "    - logging.h\n",
        "    - ndarray.h\n",
        "- needle/src/\n",
        "    - cpu_device_api.cc\n",
        "    - cuda_device_api.cc\n",
        "    - device_api.cc\n",
        "    - device_api_internal.h\n",
        "    - ndarray.cc\n",
        "- needle/python/pybind\n",
        "    - main.cc\n",
        "- needle/python\n",
        "    - backend_ndarray.py\n",
        "    - cuda_backend.py\n",
        "\n",
        "Our framework is called needle. Needle stands for necessary elements of deep learning. You can also viewed it as a sewing needle that threads through clothes to form (neural)net patterns, and the create traces for automatic differentiation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1Z8wSsI6PrU"
      },
      "source": [
        "## Creating a CUDA Tensor\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2bm_WB9uF4V"
      },
      "source": [
        "import needle as ndl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2On4NzNggDfN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZGnTUsKF1x1"
      },
      "source": [
        "We can create a CUDA tensor from the data by specifying a device keyword."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1h5iAYFfBRED"
      },
      "source": [
        "x = ndl.Tensor([1, 2, 3], dtype=\"float32\", device=ndl.cuda())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4UuEs9KAkDR",
        "outputId": "9b8a8d11-a7e0-4b40-ea9a-9f4dd0541967"
      },
      "source": [
        "x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "needle.Tensor([1. 2. 3.])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBMvL6QEBtG7",
        "outputId": "28e404bc-8329-4573-eee5-6d1d3494dbd2"
      },
      "source": [
        "x.device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "cuda(0)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJSv7D8NGfAr"
      },
      "source": [
        "y = x + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZ7hmyBVGhGd",
        "outputId": "64774237-13d6-41e0-b372-18cba1091a61"
      },
      "source": [
        "y.device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "cuda(0)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQVtUgK-f7_y",
        "outputId": "304f3889-ec6b-4c79-e5b8-396624edf523"
      },
      "source": [
        "y.numpy()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2., 3., 4.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPjNJfJsf_T9"
      },
      "source": [
        "### Key Data Structures\n",
        "\n",
        "C++ side\n",
        "- NDArray: exposes an n-dimensional array data structure\n",
        "\n",
        "Python side:\n",
        "- backend_ndarray.NDArray: wraps the C++ side of computation\n",
        "\n",
        "Pybind bridge:\n",
        "- pybind/main.cc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxKF9dcFhTy3"
      },
      "source": [
        "## Trace GPU execution\n",
        "\n",
        "Now, let us take a look at what happens when we execute the following code\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRu436EYhNko"
      },
      "source": [
        "x = ndl.Tensor([1, 2, 3], dtype=\"float32\", device=ndl.cuda())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3XeZYw1hhek"
      },
      "source": [
        "Have the following trace:\n",
        "- `autograd.Tensor.__init__`\n",
        "- `cuda_backend.CUDADevice.array`\n",
        "- `backend_ndarray.array`\n",
        "    - `backend_ndarray.empty`\n",
        "    - `_ffi.empty`\n",
        "    - `pybind/main.cc:empty`\n",
        "    - `include/needle/ndarray.h: NDArray::Empty`\n",
        "- `backend_ndarray.NDArray.copyfrom`\n",
        "    - `pybind/main.cc:copyfrombytes`\n",
        "    - `include/needle/ndarray.h: NDArray::CopyFromBytes`\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLLzZzuthhBH"
      },
      "source": [
        "y = x + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xU5PFJJ-iR7J"
      },
      "source": [
        "Have the following trace:\n",
        "\n",
        "- `cuda_backend.add_scalar`\n",
        "- `_ffi.CUDAAddScalar`\n",
        "- `include/needle/cuda_ops.h: CUDAAddScalar`\n",
        "- `src/cuda_ops.cu: CUDAAddScalar`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxAKyM6yjr_R",
        "outputId": "23a261d7-38c3-4b91-e1ef-f79e4cca52c5"
      },
      "source": [
        "y.numpy()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2., 3., 4.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4vqb_a4j2O8"
      },
      "source": [
        "Have the following trace:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMiFJmJVlD6j"
      },
      "source": [
        "## Guidelines for Reading C++/CUDA related Files\n",
        "\n",
        "The project contains around 1000 lines of scafolding code.\n",
        "You are more than welcomed to read all of them to get a full picture of the project. However, here are some files that you can feel free to skip\n",
        "\n",
        "Free to skip: you only need to know how to use them(`e.g. type make`) but not the implementation details.\n",
        "\n",
        "- CMakeLists.txt: this is used to setup the build and likely you do not need to tweak it.\n",
        "- include/needle/logging.h: A minimum glog style helper that enables `LOG(INFO) << \"message\"` and `CHECK(condition) << \"message\"`, you do not need to understand the implementation, as long as you know how to use them.\n",
        "\n",
        "Good to read: these are the files we recommend you to read and understand, but likely you do not need to update them in your homework.\n",
        "\n",
        "- device_api.h\n",
        "- ndarray.h\n",
        "- dlpack.h\n",
        "- pybind/main.cc\n",
        "\n",
        "Need to update in your homework: you will need to update these files in your homework\n",
        "\n",
        "- cuda_ops.h\n",
        "- cuda_ops.cu\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEpPbwQKkSkZ"
      },
      "source": [
        "## C++ NDArray Data Structure\n",
        "\n",
        "- Open up `include/needle/ndarray.h` NDArray is contains `shared_ptr` to a Container object\n",
        "- The container object wraps DLTensor, which is a standard data structure for defining tensors in memory\n",
        "- The actual data allocations are defined by DeviceAPI(`device_api.h`)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ONkZbUuj6Dx"
      },
      "source": [
        "## CUDA Acceleration\n",
        "\n",
        "-  Now let us open `src/cuda_ops.cu` and take a look at current implementation of GPU ops.\n",
        "- Note that all the ops takes NDArray that contains pre-allocated GPU pointers. The allocations are defined in `src/cuda_device_api.cc`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Og8N3iuZiZ4g"
      },
      "source": [
        "## Steps for adding a new operator implementation\n",
        "- Add operator declaration to needle/cuda_ops.h\n",
        "- Implement the cuda operator in src/cuda_ops.cu\n",
        "- Expose the API to python ffi through pybind/main.cc\n",
        "- Call into the API in cuda_backend.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xV1I7I2lkOJG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74OUUH2REG18"
      },
      "source": [
        "## Write Standalone Python Test Files\n",
        "\n",
        "Now that we have additional c++/cuda libraries in needle, we will need to type make in order to rebuild the library. Additionally, because the colab environment caches the old library, it is inconvenient to use the ipython cells to debug the updated library.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgLoV-_KHAM3",
        "outputId": "118fcff4-00f9-4722-b27d-e92a19ca5930"
      },
      "source": [
        "!make"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- Found pybind11: /usr/local/lib/python3.7/dist-packages/pybind11/include (found version \"2.8.0\" )\n",
            "-- Find cuda, build with cuda support\n",
            "-- Autodetected CUDA architecture(s):  3.7\n",
            "-- Configuring done\n",
            "-- Generating done\n",
            "-- Build files have been written to: /content/drive/My Drive/10714/lecture13/build\n",
            "make[1]: Entering directory '/content/drive/My Drive/10714/lecture13/build'\n",
            "make[2]: Entering directory '/content/drive/My Drive/10714/lecture13/build'\n",
            "make[3]: Entering directory '/content/drive/My Drive/10714/lecture13/build'\n",
            "make[3]: Leaving directory '/content/drive/My Drive/10714/lecture13/build'\n",
            "make[3]: Entering directory '/content/drive/My Drive/10714/lecture13/build'\n",
            "[-14%] \u001b[32m\u001b[1mLinking CXX shared module ../python/needle/_ffi/main.cpython-37m-x86_64-linux-gnu.so\u001b[0m\n",
            "make[3]: Leaving directory '/content/drive/My Drive/10714/lecture13/build'\n",
            "[ 71%] Built target main\n",
            "make[2]: Leaving directory '/content/drive/My Drive/10714/lecture13/build'\n",
            "make[1]: Leaving directory '/content/drive/My Drive/10714/lecture13/build'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dudnLHRqoKY2"
      },
      "source": [
        "\n",
        "We recommend writing separate python files and invoke them from the command line. Create a new file `tests/mytest.py` and write your local tests. This is also a common develop practice in big projects that involves python c++ FFI."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TubIHJrkn4Sk"
      },
      "source": [
        "!python tests/mytest.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ei0UR-FYoY1-"
      },
      "source": [
        "After we have building the library, we could choose to fully restart the runtime (factory reset runtime) if you want to bring the updated change back to another colab. Note that you will need to save your code changes to the drive or a private github repo."
      ]
    }
  ]
}